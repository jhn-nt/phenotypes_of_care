{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ICU Mortality Prediction Using Nursing Care Frequency\n",
    "## Severity-Stratified XGBoost Analysis \u2014 Mouthcare and Turning\n",
    "### MIMIC-IV Dataset\n",
    "\n",
    "| Parameter | Specification |\n",
    "|---|---|\n",
    "| **Outcome variable** | `hospital_expire_flag` (in-hospital mortality) |\n",
    "| **Predictive features** | LODS proxies (SOFA subscores) + APS III proxies (laboratory values, vital signs, GCS) |\n",
    "| **Care frequency variable** | `average_item_interval` \u2014 mean hours between care events per patient |\n",
    "| **Q1 definition** | Smallest `average_item_interval` = highest care frequency |\n",
    "| **Q4 definition** | Largest `average_item_interval` = lowest care frequency |\n",
    "| **Severity stratification** | Total SOFA score: Low (0\u20136), Medium (7\u201311), High (\u226512), aligned with Sepsis-3 criteria |\n",
    "| **Quartile assignment** | Within each severity stratum independently |\n",
    "| **Model A** | Trained on 70% of all quartiles within severity stratum; tested on 30% of each quartile |\n",
    "| **Model B** | Trained on 70% of Q1 only; tested on held-out 30% of Q1 and 100% of Q2, Q3, Q4 |\n",
    "| **Confidence intervals** | Bootstrap resampling, 1000 iterations, 95% CI |\n",
    "\n",
    "---\n",
    "\n",
    "**Study hypothesis:** A model trained exclusively on patients receiving the highest frequency of nursing care (Q1) will demonstrate declining discriminative performance when applied to patients with progressively lower care frequency (Q2\u2013Q4), after controlling for illness severity. This decline would indicate that care frequency independently contributes to mortality risk beyond what clinical severity scores alone can explain.\n",
    "\n",
    "**Rationale for within-severity quartile assignment:** Without severity stratification, critically ill patients naturally receive more intensive nursing care \u2014 a phenomenon known as reverse causation. Assigning quartiles within severity strata ensures that Q1 and Q4 patients share comparable illness burden, so observed differences in model performance reflect care frequency rather than underlying acuity.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Package Installation and Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import subprocess, sys\n",
    "for pkg in ['xgboost','scikit-learn','pandas','numpy','openpyxl','matplotlib','seaborn','shap']:\n",
    "    try:\n",
    "        __import__(pkg.replace('-','_'))\n",
    "    except ImportError:\n",
    "        print(f'Installing {pkg}...')\n",
    "        subprocess.check_call([sys.executable,'-m','pip','install',pkg,'-q'])\n",
    "\n",
    "import os, warnings\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as mpatches\n",
    "import seaborn as sns\n",
    "import shap\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import (\n",
    "    roc_auc_score, roc_curve, confusion_matrix,\n",
    "    precision_score, recall_score, f1_score\n",
    ")\n",
    "\n",
    "from sklearn.calibration import calibration_curve\n",
    "import xgboost as xgb\n",
    "from openpyxl import Workbook\n",
    "from openpyxl.styles import PatternFill, Font, Alignment, Border, Side\n",
    "from openpyxl.utils import get_column_letter\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "RANDOM_STATE = 42\n",
    "np.random.seed(RANDOM_STATE)\n",
    "\n",
    "plt.rcParams.update({\n",
    "    'font.family':'DejaVu Sans','font.size':11,\n",
    "    'axes.spines.top':False,'axes.spines.right':False,\n",
    "    'axes.grid':True,'grid.alpha':0.3,'figure.dpi':130\n",
    "})\n",
    "print(' All packages ready!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. File Path Configuration\n",
    "\n",
    "Modify the two directory paths below to point to the local mouthcare and turning data folders. All other configuration is handled automatically."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MOUTHCARE_FOLDER = r\"\\mouthcare\"\n",
    "TURNING_FOLDER   = r\"\\turningcare\"\n",
    "OUTPUT_FOLDER = r\"figures\"\n",
    "OUTPUT_EXCEL  = r\"mortality_results.xlsx\"\n",
    "os.makedirs(OUTPUT_FOLDER, exist_ok=True)\n",
    "\n",
    "print(f'Mouthcare : {\"\" if os.path.exists(MOUTHCARE_FOLDER) else \" NOT FOUND\"}  {MOUTHCARE_FOLDER}')\n",
    "print(f'Turning   : {\"\" if os.path.exists(TURNING_FOLDER)   else \" NOT FOUND\"}  {TURNING_FOLDER}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Analysis Constants and Feature Definitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATIENT_ID   = 'stay_id'\n",
    "MORTALITY    = 'hospital_expire_flag'\n",
    "FREQ_COL     = 'average_item_interval'  # smaller = more frequent care\n",
    "SOFA_COL     = 'SOFA'\n",
    "N_BOOTSTRAP  = 1000\n",
    "QUARTILES    = ['Q1','Q2','Q3','Q4']\n",
    "\n",
    "# \n",
    "# Severity groups based on SOFA score\n",
    "# Rationale: SOFA is the internationally validated ICU organ dysfunction\n",
    "# score used in Sepsis-3 definitions (Singer et al., JAMA 2016).\n",
    "# Cut-points 0-6 / 7-11 / 12+ are widely used in high-impact ICU literature\n",
    "# and map cleanly to mild / moderate / severe organ dysfunction.\n",
    "# \n",
    "SEVERITY_LABELS = ['Low','Medium','High']\n",
    "SEVERITY_CUTS   = [-1, 6, 11, 999]   # SOFA: Low 0-6, Medium 7-11, High 12+\n",
    "\n",
    "LODS_COLS = ['respiration','cardiovascular','liver','coagulation','renal','cns']\n",
    "APSIII_COLS = [\n",
    "    'heart_rate_min','heart_rate_max','heart_rate_mean',\n",
    "    'mbp_min','mbp_max','mbp_mean',\n",
    "    'temperature_min','temperature_max','temperature_mean',\n",
    "    'resp_rate_min','resp_rate_max','resp_rate_mean',\n",
    "    'hematocrit_min','hematocrit_max',\n",
    "    'wbc_min','wbc_max',\n",
    "    'creatinine_min','creatinine_max',\n",
    "    'bun_min','bun_max',\n",
    "    'sodium_min','sodium_max',\n",
    "    'albumin_min','albumin_max',\n",
    "    'bilirubin_total_min','bilirubin_total_max',\n",
    "    'glucose_min','glucose_max',\n",
    "    'bicarbonate_min','bicarbonate_max',\n",
    "    'gcs_min',\n",
    "]\n",
    "FEATURE_COLS = LODS_COLS + APSIII_COLS\n",
    "\n",
    "# Colours\n",
    "SEV_COLOURS = {'Low':'#2E86C1','Medium':'#E67E22','High':'#C0392B'}\n",
    "Q_COLOURS   = {'Q1':'#1A5276','Q2':'#2471A3','Q3':'#E67E22','Q4':'#C0392B'}\n",
    "MODEL_STYLES = {\n",
    "    'A \u2013 All Quartiles': {'color':'#2874A6','marker':'o','ls':'-',  'label':'Model A (all Q)'},\n",
    "    'B \u2013 Q1 Only':       {'color':'#1E8449','marker':'s','ls':'--', 'label':'Model B (Q1 trained)'},\n",
    "}\n",
    "print(' Constants set!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Data Loading and Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_folder(folder):\n",
    "    file_map = {\n",
    "        'cohort':        os.path.join(folder,'cohort.pkl'),\n",
    "        'sofa':          os.path.join(folder,'sofa.pkl'),\n",
    "        'vitals':        os.path.join(folder,'vitals.pkl'),\n",
    "        'lab':           os.path.join(folder,'lab.pkl'),\n",
    "        'gcs':           os.path.join(folder,'gcs.pkl'),\n",
    "        'proxy':         os.path.join(folder,'proxy.pkl'),\n",
    "        'comorbidities': os.path.join(folder,'comorbidities.pkl'),\n",
    "    }\n",
    "    dfs = {}\n",
    "    for name, path in file_map.items():\n",
    "        if os.path.exists(path):\n",
    "            dfs[name] = pd.read_pickle(path)\n",
    "            print(f'   {name:15s} {dfs[name].shape}')\n",
    "        else:\n",
    "            print(f'    {name}.pkl not found')\n",
    "\n",
    "    proxy_agg = dfs['proxy'].groupby(PATIENT_ID).agg(\n",
    "        average_item_interval=('average_item_interval','mean'),\n",
    "        item_volume          =('item_volume','sum'),\n",
    "        n_caregivers         =('n_caregivers','mean'),\n",
    "        icu_days             =('day','count'),\n",
    "    ).reset_index()\n",
    "\n",
    "    merged = dfs['cohort'][[PATIENT_ID, MORTALITY, 'admission_age', 'los_icu']].copy()\n",
    "    for name in ['sofa','vitals','lab','gcs','comorbidities']:\n",
    "        if name in dfs:\n",
    "            df = dfs[name].drop(columns=['subject_id','hadm_id'], errors='ignore')\n",
    "            merged = merged.merge(df, on=PATIENT_ID, how='left')\n",
    "    merged = merged.merge(proxy_agg, on=PATIENT_ID, how='left')\n",
    "    print(f'  \u2192 {len(merged):,} patients total | mortality: {merged[MORTALITY].mean()*100:.1f}%')\n",
    "    return merged\n",
    "\n",
    "print('Loading MOUTHCARE...')\n",
    "mc_df = load_folder(MOUTHCARE_FOLDER)\n",
    "print('\\nLoading TURNING...')\n",
    "turn_df = load_folder(TURNING_FOLDER)\n",
    "print('\\n Done!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Severity Stratification and Quartile Assignment\n",
    "\n",
    "Quartiles are assigned within each severity stratum separately. This design ensures that comparisons between Q1 and Q4 reflect differences in care frequency among patients of equivalent clinical severity, controlling for the confounding effect of illness acuity on care intensity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def assign_groups(df, care_label):\n",
    "    \"\"\"\n",
    "    1. Assign severity group from SOFA score (Low/Medium/High)\n",
    "    2. Within each severity group, assign Q1-Q4 by average_item_interval\n",
    "       Q1 = smallest interval = most frequent care\n",
    "       Q4 = largest interval  = least frequent care\n",
    "    3. Keep only relevant columns and drop missing\n",
    "    \"\"\"\n",
    "    avail = [c for c in FEATURE_COLS if c in df.columns]\n",
    "    keep  = [PATIENT_ID, MORTALITY, FREQ_COL, SOFA_COL] + avail\n",
    "    out   = df[[c for c in keep if c in df.columns]].copy()\n",
    "\n",
    "    # Drop rows missing mortality or frequency\n",
    "    out = out.dropna(subset=[MORTALITY, FREQ_COL]).copy()\n",
    "    out[MORTALITY] = out[MORTALITY].astype(int)\n",
    "    for col in avail + [FREQ_COL]:\n",
    "        out[col] = pd.to_numeric(out[col], errors='coerce')\n",
    "    out[SOFA_COL] = pd.to_numeric(out[SOFA_COL], errors='coerce')\n",
    "\n",
    "    #  Step 1: Severity group from SOFA \n",
    "    out['severity'] = pd.cut(\n",
    "        out[SOFA_COL],\n",
    "        bins=SEVERITY_CUTS,\n",
    "        labels=SEVERITY_LABELS,\n",
    "        right=True\n",
    "    ).astype(str)\n",
    "    out.loc[out[SOFA_COL].isna(), 'severity'] = 'Unknown'\n",
    "\n",
    "    #  Step 2: Quartiles WITHIN each severity group \n",
    "    # Q1 = smallest average_item_interval = most frequent care\n",
    "    out['quartile'] = out.groupby('severity', group_keys=False)[FREQ_COL].transform(\n",
    "        lambda x: pd.qcut(x, q=4, labels=QUARTILES, duplicates='drop')\n",
    "    )\n",
    "\n",
    "    # Drop patients whose quartile couldn't be assigned (rare edge case)\n",
    "    n_before = len(out)\n",
    "    out = out.dropna(subset=['quartile']).copy()\n",
    "    out = out[out['severity'] != 'Unknown'].copy()\n",
    "    n_dropped = n_before - len(out)\n",
    "    if n_dropped > 0:\n",
    "        print(f'    Dropped {n_dropped} patients (missing SOFA or unassignable quartile)')\n",
    "\n",
    "    #  Step 3: Verification printout \n",
    "    print(f'\\n{\"\"*60}')\n",
    "    print(f'  {care_label} \u2014 group verification')\n",
    "    print(f'  Total patients: {len(out):,} | Mortality: {out[MORTALITY].mean()*100:.1f}%')\n",
    "    print(f'\\n  Mean SOFA by severity (should differ clearly):')\n",
    "    print(' ', out.groupby('severity')[SOFA_COL].mean().round(2).reindex(SEVERITY_LABELS).to_dict())\n",
    "    print(f'\\n  Mean SOFA by quartile within severity (should be SIMILAR \u2014 proves balance):')\n",
    "    sofa_check = out.groupby(['severity','quartile'], observed=True)[SOFA_COL].mean().round(2).unstack()\n",
    "    print(sofa_check.reindex(SEVERITY_LABELS).to_string())\n",
    "    print(f'\\n  Mean interval by quartile within severity (Q1 should be smallest):')\n",
    "    interval_check = out.groupby(['severity','quartile'], observed=True)[FREQ_COL].mean().round(3).unstack()\n",
    "    print(interval_check.reindex(SEVERITY_LABELS).to_string())\n",
    "    print(f'\\n  Mortality by quartile within severity:')\n",
    "    mort_check = out.groupby(['severity','quartile'], observed=True)[MORTALITY].mean().round(3).unstack()\n",
    "    print(mort_check.reindex(SEVERITY_LABELS).to_string())\n",
    "    print(f'  (Hypothesis predicts mortality should increase Q1\u2192Q4)')\n",
    "\n",
    "    return out, avail\n",
    "\n",
    "print('Assigning groups for MOUTHCARE...')\n",
    "mc_data, mc_feats = assign_groups(mc_df, 'Mouthcare')\n",
    "print('\\nAssigning groups for TURNING...')\n",
    "turn_data, turn_feats = assign_groups(turn_df, 'Turning')\n",
    "print('\\n Group assignment complete!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Model Training Utilities, Evaluation Metrics, and Bootstrap Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stratified_split(df, test_size=0.3):\n",
    "    \"\"\"70/30 stratified split preserving mortality rate per quartile.\"\"\"\n",
    "    trains, tests = [], []\n",
    "    for q in QUARTILES:\n",
    "        sub = df[df['quartile'] == q]\n",
    "        if len(sub) < 10:\n",
    "            tests.append(sub)\n",
    "            continue\n",
    "        try:\n",
    "            tr, te = train_test_split(sub, test_size=test_size,\n",
    "                                      stratify=sub[MORTALITY], random_state=RANDOM_STATE)\n",
    "        except ValueError:\n",
    "            tr, te = train_test_split(sub, test_size=test_size, random_state=RANDOM_STATE)\n",
    "        trains.append(tr)\n",
    "        tests.append(te)\n",
    "    return pd.concat(trains), pd.concat(tests)\n",
    "\n",
    "\n",
    "def train_xgb(X_train, y_train):\n",
    "    \"\"\"XGBoost with class imbalance correction.\"\"\"\n",
    "    neg, pos = (y_train == 0).sum(), (y_train == 1).sum()\n",
    "    model = xgb.XGBClassifier(\n",
    "        n_estimators=300, max_depth=4, learning_rate=0.05,\n",
    "        subsample=0.8, colsample_bytree=0.8,\n",
    "        scale_pos_weight=neg/pos if pos > 0 else 1,\n",
    "        eval_metric='logloss', random_state=RANDOM_STATE, n_jobs=-1\n",
    "    )\n",
    "    model.fit(X_train, y_train)\n",
    "    return model\n",
    "\n",
    "\n",
    "def bootstrap_metrics(y_true, y_pred, y_prob, n=N_BOOTSTRAP):\n",
    "    \"\"\"Bootstrap 95% CI for all metrics.\"\"\"\n",
    "    rng = np.random.default_rng(RANDOM_STATE)\n",
    "    idx = np.arange(len(y_true))\n",
    "    yt_a, yp_a, ypr_a = map(np.array, [y_true, y_pred, y_prob])\n",
    "    store = {k: [] for k in ['auroc','sens','spec','ppv','npv','f1']}\n",
    "    for _ in range(n):\n",
    "        b = rng.choice(idx, size=len(idx), replace=True)\n",
    "        yt, yp, ypr = yt_a[b], yp_a[b], ypr_a[b]\n",
    "        if len(np.unique(yt)) < 2:\n",
    "            continue\n",
    "        try:\n",
    "            tn, fp, fn, tp = confusion_matrix(yt, yp).ravel()\n",
    "        except:\n",
    "            continue\n",
    "        store['auroc'].append(roc_auc_score(yt, ypr))\n",
    "        store['sens'].append(tp/(tp+fn) if (tp+fn) > 0 else 0)\n",
    "        store['spec'].append(tn/(tn+fp) if (tn+fp) > 0 else 0)\n",
    "        store['ppv'].append(tp/(tp+fp) if (tp+fp) > 0 else 0)\n",
    "        store['npv'].append(tn/(tn+fn) if (tn+fn) > 0 else 0)\n",
    "        store['f1'].append(f1_score(yt, yp, zero_division=0))\n",
    "    out = {}\n",
    "    for k, v in store.items():\n",
    "        out[k] = (np.mean(v), np.percentile(v,2.5), np.percentile(v,97.5)) if v else (np.nan,)*3\n",
    "    return out\n",
    "\n",
    "\n",
    "def fmt(m, lo, hi):\n",
    "    if any(isinstance(x,float) and np.isnan(x) for x in [m,lo,hi]):\n",
    "        return 'N/A'\n",
    "    return f'{m:.3f} ({lo:.3f}\u2013{hi:.3f})'\n",
    "\n",
    "\n",
    "def evaluate(model, X_test, y_test, feats, train_med,\n",
    "             label, care, model_name, severity):\n",
    "    \"\"\"Run model on test set and compute all metrics.\"\"\"\n",
    "    row = {'Care Type':care, 'Severity':severity, 'Model':model_name,\n",
    "           'Test Set':label, 'N':len(X_test),\n",
    "           'Mortality%': round(y_test.mean()*100,1) if len(y_test)>0 else None}\n",
    "    Xte = X_test[feats].fillna(train_med)\n",
    "    if len(Xte) == 0 or y_test.nunique() < 2:\n",
    "        for c in ['AUROC','AUROC_lo','AUROC_hi','AUROC_CI',\n",
    "                  'Sensitivity','Specificity','PPV','NPV','F1']:\n",
    "            row[c] = None\n",
    "        return row, None, None\n",
    "    yprob = model.predict_proba(Xte)[:, 1]\n",
    "    # Use Youden's J to select threshold\n",
    "    fpr, tpr, thresholds = roc_curve(y_test, yprob)\n",
    "    threshold = thresholds[np.argmax(tpr - fpr)]\n",
    "    ypred = (yprob >= threshold).astype(int)\n",
    "    bs = bootstrap_metrics(y_test, ypred, yprob)\n",
    "    am, alo, ahi = bs['auroc']\n",
    "    row.update({\n",
    "        'AUROC':    round(am,3)  if not np.isnan(am)  else None,\n",
    "        'AUROC_lo': round(alo,3) if not np.isnan(alo) else None,\n",
    "        'AUROC_hi': round(ahi,3) if not np.isnan(ahi) else None,\n",
    "        'AUROC_CI':    fmt(am,alo,ahi),\n",
    "        'Sensitivity': fmt(*bs['sens']),\n",
    "        'Specificity': fmt(*bs['spec']),\n",
    "        'PPV':         fmt(*bs['ppv']),\n",
    "        'NPV':         fmt(*bs['npv']),\n",
    "        'F1':          fmt(*bs['f1']),\n",
    "    })\n",
    "    return row, yprob, y_test\n",
    "\n",
    "print(' Helper functions ready!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Model Training and Evaluation\n",
    "\n",
    "For each care type (mouthcare, turning) and each severity stratum (Low, Medium, High):\n",
    "\n",
    "- **Model A**: Trained on 70% of all quartiles combined (stratified random sample). Tested on the held-out 30% of each quartile separately to assess overall model discrimination.\n",
    "- **Model B**: Trained on 70% of Q1 patients only. Tested on the held-out 30% of Q1 and on the complete Q2, Q3, and Q4 populations to assess generalisation from high-frequency to low-frequency care patients.\n",
    "\n",
    "All splits are stratified by mortality outcome to preserve event rates across training and test sets.\n",
    "\n",
    "*Note: Bootstrap resampling (n=1000) is performed for each test set. Runtime is approximately 10\u201320 minutes.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_results       = []\n",
    "calibration_store = []  # (care, severity, model, quartile, y_true, y_prob)\n",
    "shap_store        = {}  # (care, severity, model) -> (model, X_train, feats)\n",
    "roc_store         = []  # (care, severity, model, quartile, fpr, tpr, auc)\n",
    "\n",
    "def run_severity_group(data, feats, care_label, sev_label):\n",
    "    \"\"\"Train Model A and Model B for one care type + severity group.\"\"\"\n",
    "    results = []\n",
    "    tag = f'{care_label} | {sev_label}'\n",
    "\n",
    "    if data['quartile'].nunique() < 2:\n",
    "        print(f'    [{tag}] Not enough quartile variation, skipping.')\n",
    "        return results\n",
    "\n",
    "    train_all, test_all = stratified_split(data)\n",
    "    train_med = train_all[feats].median()\n",
    "\n",
    "    print(f'    Splits: train={len(train_all)} test={len(test_all)} '\n",
    "          f'(train mortality={train_all[MORTALITY].mean()*100:.1f}%)')\n",
    "\n",
    "    # \n",
    "    # MODEL A \u2014 trained on all quartiles combined\n",
    "    # \n",
    "    Xtr = train_all[feats].fillna(train_med)\n",
    "    ytr = train_all[MORTALITY]\n",
    "    try:\n",
    "        model_A = train_xgb(Xtr, ytr)\n",
    "    except Exception as e:\n",
    "        print(f'    [{tag}] Model A failed: {e}')\n",
    "        return results\n",
    "    shap_store[(care_label, sev_label, 'A \u2013 All Quartiles')] = (model_A, Xtr, feats)\n",
    "\n",
    "    # Test A on 30% of each quartile\n",
    "    for q in QUARTILES:\n",
    "        te = test_all[test_all['quartile'] == q]\n",
    "        if len(te) == 0:\n",
    "            continue\n",
    "        row, yp, yt = evaluate(model_A, te, te[MORTALITY], feats, train_med,\n",
    "                               f'Test {q} (30%)', care_label, 'A \u2013 All Quartiles', sev_label)\n",
    "        results.append(row)\n",
    "        if yp is not None:\n",
    "            calibration_store.append((care_label,sev_label,'A \u2013 All Quartiles',q,yt,yp))\n",
    "            fpr_v,tpr_v,_ = roc_curve(yt,yp)\n",
    "            roc_store.append((care_label,sev_label,'A \u2013 All Quartiles',q,fpr_v,tpr_v,row['AUROC']))\n",
    "\n",
    "    # \n",
    "    # MODEL B \u2014 trained on Q1 only (most frequent)\n",
    "    # \n",
    "    q1_tr = train_all[train_all['quartile'] == 'Q1']\n",
    "    if len(q1_tr) < 20:\n",
    "        print(f'    [{tag}] Too few Q1 training patients ({len(q1_tr)}), skipping Model B.')\n",
    "        return results\n",
    "    Xtr_B  = q1_tr[feats].fillna(q1_tr[feats].median())\n",
    "    ytr_B  = q1_tr[MORTALITY]\n",
    "    q1_med = Xtr_B.median()\n",
    "\n",
    "    print(f'    Model B training: n={len(Xtr_B)} Q1 patients '\n",
    "          f'(mortality={ytr_B.mean()*100:.1f}%)')\n",
    "\n",
    "    try:\n",
    "        model_B = train_xgb(Xtr_B, ytr_B)\n",
    "    except Exception as e:\n",
    "        print(f'    [{tag}] Model B failed: {e}')\n",
    "        return results\n",
    "    shap_store[(care_label, sev_label, 'B \u2013 Q1 Only')] = (model_B, Xtr_B, feats)\n",
    "\n",
    "    # Test B on 30% Q1 held-out\n",
    "    q1_te = test_all[test_all['quartile'] == 'Q1']\n",
    "    row, yp, yt = evaluate(model_B, q1_te, q1_te[MORTALITY], feats, q1_med,\n",
    "                           'Test Q1 (30%)', care_label, 'B \u2013 Q1 Only', sev_label)\n",
    "    results.append(row)\n",
    "    if yp is not None:\n",
    "        calibration_store.append((care_label,sev_label,'B \u2013 Q1 Only','Q1',yt,yp))\n",
    "        fpr_v,tpr_v,_ = roc_curve(yt,yp)\n",
    "        roc_store.append((care_label,sev_label,'B \u2013 Q1 Only','Q1',fpr_v,tpr_v,row['AUROC']))\n",
    "\n",
    "    # Test B on 100% of Q2, Q3, Q4\n",
    "    for q in ['Q2','Q3','Q4']:\n",
    "        te = data[data['quartile'] == q]\n",
    "        if len(te) == 0:\n",
    "            continue\n",
    "        row, yp, yt = evaluate(model_B, te, te[MORTALITY], feats, q1_med,\n",
    "                               f'Test {q} (100%)', care_label, 'B \u2013 Q1 Only', sev_label)\n",
    "        results.append(row)\n",
    "        if yp is not None:\n",
    "            calibration_store.append((care_label,sev_label,'B \u2013 Q1 Only',q,yt,yp))\n",
    "            fpr_v,tpr_v,_ = roc_curve(yt,yp)\n",
    "            roc_store.append((care_label,sev_label,'B \u2013 Q1 Only',q,fpr_v,tpr_v,row['AUROC']))\n",
    "    return results\n",
    "\n",
    "\n",
    "def run_pipeline(data, feats, care_label):\n",
    "    print(f'\\n{\"\"*60}\\n  {care_label}\\n{\"\"*60}')\n",
    "    res = []\n",
    "    for sev in SEVERITY_LABELS:\n",
    "        sub = data[data['severity'] == sev].copy()\n",
    "        print(f'\\n   {sev} severity (n={len(sub):,}, '\n",
    "              f'mortality={sub[MORTALITY].mean()*100:.1f}%)')\n",
    "        if len(sub) < 80:\n",
    "            print('      Too few patients, skipping.')\n",
    "            continue\n",
    "        res += run_severity_group(sub, feats, care_label, sev)\n",
    "    return res\n",
    "\n",
    "\n",
    "all_results  = run_pipeline(mc_data,   mc_feats,   'Mouthcare')\n",
    "all_results += run_pipeline(turn_data, turn_feats, 'Turning')\n",
    "\n",
    "COL_ORDER  = ['Care Type','Severity','Model','Test Set','N','Mortality%',\n",
    "              'AUROC','AUROC_lo','AUROC_hi','AUROC_CI',\n",
    "              'Sensitivity','Specificity','PPV','NPV','F1']\n",
    "results_df = pd.DataFrame(all_results)\n",
    "results_df = results_df[[c for c in COL_ORDER if c in results_df.columns]]\n",
    "print(f'\\n\\n Done! {len(results_df)} result rows.')\n",
    "print(results_df[['Care Type','Severity','Model','Test Set','N','Mortality%','AUROC','AUROC_CI']].to_string(index=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Descriptive Analysis \u2014 Mortality Rate by Severity Stratum and Care Frequency Quartile\n",
    "\n",
    "This table constitutes the primary descriptive evidence. A systematic increase in mortality rate from Q1 to Q4 within each severity stratum, after accounting for illness acuity, would provide direct support for the hypothesis that care frequency independently influences patient outcomes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mortality_table(data, care_label):\n",
    "    rows = []\n",
    "    for sev in SEVERITY_LABELS:\n",
    "        sub = data[data['severity'] == sev]\n",
    "        for q in QUARTILES:\n",
    "            qdf = sub[sub['quartile'] == q]\n",
    "            if len(qdf) == 0:\n",
    "                continue\n",
    "            rows.append({\n",
    "                'Care Type':          care_label,\n",
    "                'Severity':           sev,\n",
    "                'Quartile':           q,\n",
    "                'N':                  len(qdf),\n",
    "                'Deaths':             int(qdf[MORTALITY].sum()),\n",
    "                'Mortality%':         round(qdf[MORTALITY].mean()*100, 1),\n",
    "                'Mean Interval (hrs)':round(qdf[FREQ_COL].mean(), 3),\n",
    "                'Mean SOFA':          round(qdf[SOFA_COL].mean(), 2),\n",
    "            })\n",
    "    return pd.DataFrame(rows)\n",
    "\n",
    "mc_mort   = mortality_table(mc_data,   'Mouthcare')\n",
    "turn_mort = mortality_table(turn_data, 'Turning')\n",
    "mort_tbl  = pd.concat([mc_mort, turn_mort], ignore_index=True)\n",
    "\n",
    "print('=== MOUTHCARE \u2014 Mortality by Severity \u00d7 Quartile ===')\n",
    "print(mc_mort.to_string(index=False))\n",
    "print('\\n=== TURNING \u2014 Mortality by Severity \u00d7 Quartile ===')\n",
    "print(turn_mort.to_string(index=False))\n",
    "print('\\n(Q1=most frequent care, Q4=least frequent care)')\n",
    "print('Key check: Mean SOFA should be similar across Q1-Q4 within each severity row')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. AUROC Summary \u2014 Pivot Table and Heatmap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def auc_pivot(results_df, care_label, model_name):\n",
    "    sub = results_df[\n",
    "        (results_df['Care Type'] == care_label) &\n",
    "        (results_df['Model'] == model_name)\n",
    "    ].copy()\n",
    "    sub['Q'] = sub['Test Set'].str.extract(r'(Q\\d)')\n",
    "    pivot = sub.pivot_table(index='Severity', columns='Q', values='AUROC', aggfunc='first')\n",
    "    existing_q = [q for q in QUARTILES if q in pivot.columns]\n",
    "    pivot = pivot[existing_q]\n",
    "    pivot.index = pd.CategoricalIndex(pivot.index, categories=SEVERITY_LABELS, ordered=True)\n",
    "    return pivot.sort_index()\n",
    "\n",
    "fig, axes = plt.subplots(2, 2, figsize=(14, 9))\n",
    "titles = [\n",
    "    ('Mouthcare','A \u2013 All Quartiles','Mouthcare \u2014 Model A\\n(trained on all Q within severity)'),\n",
    "    ('Mouthcare','B \u2013 Q1 Only',      'Mouthcare \u2014 Model B\\n(trained on Q1 only within severity)'),\n",
    "    ('Turning',  'A \u2013 All Quartiles','Turning \u2014 Model A\\n(trained on all Q within severity)'),\n",
    "    ('Turning',  'B \u2013 Q1 Only',      'Turning \u2014 Model B\\n(trained on Q1 only within severity)'),\n",
    "]\n",
    "for ax, (care, model, title) in zip(axes.flat, titles):\n",
    "    try:\n",
    "        piv = auc_pivot(results_df, care, model)\n",
    "        sns.heatmap(piv.astype(float), annot=True, fmt='.3f',\n",
    "                    cmap='RdYlGn', vmin=0.50, vmax=0.85,\n",
    "                    ax=ax, linewidths=0.5, linecolor='white',\n",
    "                    cbar_kws={'label':'AUROC'})\n",
    "        ax.set_title(title, fontweight='bold', fontsize=10)\n",
    "        ax.set_xlabel('Mouthcare/Turning Quartile\\n(Q1=most frequent, Q4=least frequent)', fontsize=9)\n",
    "        ax.set_ylabel('Severity Group (SOFA)', fontsize=9)\n",
    "    except Exception as e:\n",
    "        ax.text(0.5,0.5,f'No data\\n{e}',ha='center',va='center',transform=ax.transAxes)\n",
    "\n",
    "plt.suptitle('AUROC Heatmap \u2014 Severity-Stratified Models\\n'\n",
    "             'Hypothesis (Model B): AUROC should DECREASE left\u2192right within each severity row',\n",
    "             fontsize=12, fontweight='bold')\n",
    "plt.tight_layout()\n",
    "plt.savefig(os.path.join(OUTPUT_FOLDER,'fig1_auc_heatmap.png'), dpi=150, bbox_inches='tight')\n",
    "plt.show()\n",
    "print('Saved: fig1_auc_heatmap.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Discriminative Performance \u2014 AUROC with 95% Bootstrap Confidence Intervals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_auroc_lines(results_df, care_label, save_path):\n",
    "    sevs = SEVERITY_LABELS\n",
    "    fig, axes = plt.subplots(1, len(sevs), figsize=(5*len(sevs), 5), sharey=True)\n",
    "\n",
    "    for ax, sev in zip(axes, sevs):\n",
    "        sub = results_df[\n",
    "            (results_df['Care Type'] == care_label) &\n",
    "            (results_df['Severity'] == sev)\n",
    "        ]\n",
    "        for mname, style in MODEL_STYLES.items():\n",
    "            mdf = sub[sub['Model'] == mname].copy()\n",
    "            mdf['Q'] = mdf['Test Set'].str.extract(r'(Q\\d)')\n",
    "            mdf = mdf.dropna(subset=['Q','AUROC']).sort_values('Q')\n",
    "            if len(mdf) == 0:\n",
    "                continue\n",
    "            x    = np.arange(len(mdf))\n",
    "            auc  = mdf['AUROC'].values.astype(float)\n",
    "            lo   = mdf['AUROC_lo'].values.astype(float)\n",
    "            hi   = mdf['AUROC_hi'].values.astype(float)\n",
    "            yerr = np.array([auc-lo, hi-auc])\n",
    "            ax.errorbar(x, auc, yerr=yerr,\n",
    "                        color=style['color'], marker=style['marker'],\n",
    "                        linestyle=style['ls'], linewidth=2, markersize=8,\n",
    "                        capsize=5, capthick=2, label=style['label'],\n",
    "                        ecolor=style['color'], alpha=0.9)\n",
    "            for xi, ai in enumerate(auc):\n",
    "                ax.annotate(f'{ai:.3f}', (xi,ai),\n",
    "                            textcoords='offset points', xytext=(0,10),\n",
    "                            ha='center', fontsize=8, color=style['color'], fontweight='bold')\n",
    "\n",
    "        ax.axhline(0.5, color='grey', ls=':', lw=1, alpha=0.6, label='Chance (0.5)')\n",
    "        ax.axhline(0.7, color='#E67E22', ls=':', lw=1, alpha=0.5, label='Good (0.7)')\n",
    "        ax.set_xticks(range(len(QUARTILES)))\n",
    "        ax.set_xticklabels(['Q1\\n(most\\nfrequent)','Q2','Q3','Q4\\n(least\\nfrequent)'], fontsize=9)\n",
    "        ax.set_xlabel('Test Quartile', fontsize=10)\n",
    "        ax.set_ylim(0.35, 1.02)\n",
    "        ax.set_title(f'SOFA {sev}\\n(SOFA {\"0\u20136\" if sev==\"Low\" else \"7\u201311\" if sev==\"Medium\" else \"\u226512\"})',\n",
    "                     fontweight='bold', fontsize=11)\n",
    "        ax.set_ylabel('AUROC (95% CI)', fontsize=10)\n",
    "        ax.legend(fontsize=8, loc='lower left')\n",
    "\n",
    "    fig.suptitle(f'{care_label} \u2014 AUROC by Severity Group and Quartile\\n'\n",
    "                 f'Model B hypothesis: green dashed line should slope DOWNWARD Q1\u2192Q4',\n",
    "                 fontsize=12, fontweight='bold', y=1.02)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(save_path, bbox_inches='tight', dpi=150)\n",
    "    plt.show()\n",
    "    print(f'  Saved: {save_path}')\n",
    "\n",
    "plot_auroc_lines(results_df, 'Mouthcare',\n",
    "                 os.path.join(OUTPUT_FOLDER,'fig2a_auroc_mouthcare.png'))\n",
    "plot_auroc_lines(results_df, 'Turning',\n",
    "                 os.path.join(OUTPUT_FOLDER,'fig2b_auroc_turning.png'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 11. Model Calibration Analysis\n",
    "\n",
    "Calibration curves compare the model's predicted mortality probability against observed mortality rates in each quartile. For Model B, curves falling above the diagonal in Q3 and Q4 indicate systematic under-prediction of mortality risk \u2014 that is, the model assigns lower risk scores than patients actually experience. This pattern would indicate that low-care patients carry mortality risk not captured by clinical severity features alone, consistent with the study hypothesis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_calibration_grid(care_label, model_name, save_path):\n",
    "    sevs = SEVERITY_LABELS\n",
    "    fig, axes = plt.subplots(1, len(sevs), figsize=(5*len(sevs), 5))\n",
    "\n",
    "    for ax, sev in zip(axes, sevs):\n",
    "        entries = [(q,yt,yp) for (cl,sl,mn,q,yt,yp) in calibration_store\n",
    "                   if cl==care_label and sl==sev and mn==model_name]\n",
    "        ax.plot([0,1],[0,1],'k--', lw=1.2, label='Perfect calibration', alpha=0.6)\n",
    "        for q, yt, yp in sorted(entries, key=lambda x: x[0]):\n",
    "            if len(yt) < 20:\n",
    "                continue\n",
    "            try:\n",
    "                fp, mp = calibration_curve(np.array(yt), np.array(yp),\n",
    "                                           n_bins=8, strategy='quantile')\n",
    "                col = Q_COLOURS.get(q,'grey')\n",
    "                ax.plot(mp, fp, marker='o', lw=2, color=col,\n",
    "                        label=f'{q} (n={len(yt)})', markersize=6)\n",
    "                ax.fill_between(mp, mp, fp, alpha=0.07, color=col)\n",
    "            except:\n",
    "                pass\n",
    "        ax.set_xlabel('Mean Predicted Probability', fontsize=10)\n",
    "        ax.set_ylabel('Actual Mortality Rate', fontsize=10)\n",
    "        ax.set_title(f'SOFA {sev}\\n(SOFA {\"0\u20136\" if sev==\"Low\" else \"7\u201311\" if sev==\"Medium\" else \"\u226512\"})',\n",
    "                     fontweight='bold')\n",
    "        ax.legend(title='Test Quartile', fontsize=8)\n",
    "        ax.set_xlim(0,1); ax.set_ylim(0,1)\n",
    "        ax.text(0.52,0.04,'Above diagonal = model\\nunder-predicts mortality',\n",
    "                fontsize=7.5,color='#C0392B',alpha=0.8,\n",
    "                bbox=dict(boxstyle='round,pad=0.3',facecolor='#FDEDEC',alpha=0.5))\n",
    "\n",
    "    fig.suptitle(f'{care_label} \u2014 Calibration Curves | {model_name}\\n'\n",
    "                 f'Q3/Q4 above diagonal \u2192 model under-predicts their mortality \u2192 supports hypothesis',\n",
    "                 fontsize=11, fontweight='bold', y=1.02)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(save_path, bbox_inches='tight', dpi=150)\n",
    "    plt.show()\n",
    "    print(f'  Saved: {save_path}')\n",
    "\n",
    "for care in ['Mouthcare','Turning']:\n",
    "    plot_calibration_grid(\n",
    "        care, 'B \u2013 Q1 Only',\n",
    "        os.path.join(OUTPUT_FOLDER, f'fig3_calibration_{care.lower()}_modelB.png')\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## 12b. Calibration Quality \u2014 Brier Score Analysis\n\nFor each severity stratum and model (Model A and Model B), the Brier score is computed on each test quartile (Q1\u2013Q4) using predicted probabilities. Bootstrap resampling (1,000 iterations) is used to derive 95% confidence intervals.\n\nThe Brier score measures mean squared error between predicted probabilities and actual binary outcomes, ranging from 0 (perfect) to 1 (worst). A score of 0.25 corresponds to uninformative prediction at 50% prevalence. Lower values indicate better probabilistic calibration.\n\nFor the study hypothesis, Model B is expected to show increasing Brier scores when generalised from Q1 to Q2\u2013Q4, reflecting progressively poorer probability calibration among patients receiving less frequent care."
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# \u2500\u2500 Brier Score Analysis \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\n# Uses calibration_store: list of (care, severity, model, quartile, y_true, y_prob)\n# Computes Brier score from predicted probabilities with 1000-iteration bootstrap CI.\n\nfrom sklearn.metrics import brier_score_loss\n\ndef bootstrap_brier(y_true, y_prob, n=1000, seed=42):\n    \"\"\"\n    Bootstrap 95% CI for Brier score.\n    Uses predicted probabilities directly (not class labels).\n    Lower Brier score = better calibration.\n    \"\"\"\n    rng      = np.random.default_rng(seed)\n    y_true_a = np.array(y_true)\n    y_prob_a = np.array(y_prob)\n    idx      = np.arange(len(y_true_a))\n    scores   = []\n    for _ in range(n):\n        b = rng.choice(idx, size=len(idx), replace=True)\n        if len(np.unique(y_true_a[b])) < 2:\n            continue\n        scores.append(brier_score_loss(y_true_a[b], y_prob_a[b]))\n    if not scores:\n        return np.nan, np.nan, np.nan\n    return np.mean(scores), np.percentile(scores, 2.5), np.percentile(scores, 97.5)\n\n\n# \u2500\u2500 Build tidy results dataframe \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\nbrier_rows = []\nfor (care, severity, model, quartile, y_true, y_prob) in calibration_store:\n    if len(y_true) < 10:\n        continue\n    bs, lo, hi = bootstrap_brier(y_true, y_prob)\n    brier_rows.append({\n        'care_type':      care,\n        'severity_group': severity,\n        'model_type':     model,\n        'test_quartile':  quartile,\n        'N':              len(y_true),\n        'mortality_pct':  round(np.mean(y_true) * 100, 1),\n        'brier_score':    round(bs, 4),\n        'ci_lower':       round(lo, 4),\n        'ci_upper':       round(hi, 4),\n    })\n\nbrier_df = pd.DataFrame(brier_rows)\n\n# \u2500\u2500 Summary table \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\nprint('Brier Score Summary Table')\nprint('=' * 90)\nsummary = brier_df[[\n    'care_type','severity_group','model_type','test_quartile',\n    'N','mortality_pct','brier_score','ci_lower','ci_upper'\n]].copy()\nsummary['brier_score'] = summary['brier_score'].map('{:.4f}'.format)\nsummary['ci_lower']    = summary['ci_lower'].map('{:.4f}'.format)\nsummary['ci_upper']    = summary['ci_upper'].map('{:.4f}'.format)\npd.set_option('display.max_columns', None)\npd.set_option('display.width', 200)\npd.set_option('display.max_rows', 200)\nprint(summary.to_string(index=False))\n\n\n# \u2500\u2500 Plot: Brier score with bootstrap CI error bars \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\ndef plot_brier(brier_df, care_label, save_path):\n    df   = brier_df[brier_df['care_type'] == care_label].copy()\n    sevs = [s for s in SEVERITY_LABELS if s in df['severity_group'].values]\n    if not sevs:\n        print(f'No Brier data for {care_label}')\n        return\n\n    fig, axes = plt.subplots(1, len(sevs), figsize=(5 * len(sevs), 5), sharey=True)\n    if len(sevs) == 1:\n        axes = [axes]\n\n    styles = {\n        'A \u2013 All Quartiles': {'color':'#2874A6','marker':'o','ls':'-',\n                              'label':'Model A (all quartiles)'},\n        'B \u2013 Q1 Only':       {'color':'#B7410E','marker':'s','ls':'--',\n                              'label':'Model B (Q1 trained)'},\n    }\n\n    for ax, sev in zip(axes, sevs):\n        sub = df[df['severity_group'] == sev]\n        for mname, style in styles.items():\n            mdf = sub[sub['model_type'] == mname].sort_values('test_quartile')\n            if len(mdf) == 0:\n                continue\n            x    = np.arange(len(mdf))\n            bm   = mdf['brier_score'].values.astype(float)\n            lo   = mdf['ci_lower'].values.astype(float)\n            hi   = mdf['ci_upper'].values.astype(float)\n            yerr = np.array([bm - lo, hi - bm])\n            ax.errorbar(x, bm, yerr=yerr,\n                        color=style['color'], marker=style['marker'],\n                        linestyle=style['ls'], linewidth=2, markersize=8,\n                        capsize=5, capthick=2, label=style['label'],\n                        ecolor=style['color'], alpha=0.9)\n            for xi, bi in enumerate(bm):\n                ax.annotate(f'{bi:.3f}', (xi, bi),\n                            textcoords='offset points', xytext=(0, 8),\n                            ha='center', fontsize=8.5,\n                            color=style['color'], fontweight='bold')\n\n        ax.set_xticks(range(len(QUARTILES)))\n        ax.set_xticklabels(QUARTILES, fontsize=10)\n        ax.set_xlabel('Test Quartile', fontsize=10)\n        ax.set_title(sev, fontweight='bold', fontsize=11)\n        if ax == axes[0]:\n            ax.set_ylabel('Brier Score (lower = better)', fontsize=10)\n        ax.legend(fontsize=8.5, loc='upper left')\n\n    fig.suptitle(\n        f'{care_label} \u2014 Brier Score by Test Quartile\\n'\n        f'(Error bars = 95% bootstrap CI, n=1000 iterations)',\n        fontsize=13, fontweight='bold', y=1.02\n    )\n    plt.tight_layout()\n    plt.savefig(save_path, bbox_inches='tight', dpi=150)\n    plt.show()\n    print(f'Saved: {save_path}')\n\n\nfor care in ['Mouthcare', 'Turning']:\n    plot_brier(\n        brier_df, care,\n        os.path.join(OUTPUT_FOLDER, f'fig_brier_{care.lower()}.png')\n    )\n"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 12. Feature Importance \u2014 SHAP Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RENAME = {\n",
    "    'gcs_min':'GCS (min)','respiration':'SOFA Respiration',\n",
    "    'cardiovascular':'SOFA Cardiovascular','cns':'SOFA CNS',\n",
    "    'renal':'SOFA Renal','liver':'SOFA Liver','coagulation':'SOFA Coagulation',\n",
    "    'mbp_min':'MBP (min)','mbp_mean':'MBP (mean)','mbp_max':'MBP (max)',\n",
    "    'heart_rate_min':'HR (min)','heart_rate_mean':'HR (mean)',\n",
    "    'resp_rate_mean':'Resp Rate (mean)','temperature_mean':'Temp (mean)',\n",
    "    'creatinine_max':'Creatinine (max)','bun_max':'BUN (max)',\n",
    "    'albumin_min':'Albumin (min)','bicarbonate_min':'Bicarbonate (min)',\n",
    "    'bilirubin_total_max':'Bilirubin (max)','wbc_max':'WBC (max)',\n",
    "}\n",
    "SOFA_SET = {'SOFA Respiration','SOFA Cardiovascular','SOFA CNS',\n",
    "            'SOFA Renal','SOFA Liver','SOFA Coagulation'}\n",
    "\n",
    "def plot_shap_grid(care_label, model_name, save_path, top_n=12):\n",
    "    sevs = [s for s in SEVERITY_LABELS\n",
    "            if (care_label, s, model_name) in shap_store]\n",
    "    if not sevs:\n",
    "        print(f'  No SHAP data for {care_label} | {model_name}')\n",
    "        return\n",
    "    fig, axes = plt.subplots(1, len(sevs), figsize=(6*len(sevs), 5))\n",
    "    if len(sevs) == 1:\n",
    "        axes = [axes]\n",
    "    for ax, sev in zip(axes, sevs):\n",
    "        model, X_train, feats = shap_store[(care_label, sev, model_name)]\n",
    "        sample = X_train.sample(min(400, len(X_train)), random_state=RANDOM_STATE)\n",
    "        explainer   = shap.TreeExplainer(model)\n",
    "        shap_values = explainer.shap_values(sample)\n",
    "        mean_abs    = pd.Series(np.abs(shap_values).mean(axis=0), index=feats)\n",
    "        top         = mean_abs.nlargest(top_n).sort_values()\n",
    "        top.index   = [RENAME.get(f,f) for f in top.index]\n",
    "        colors      = ['#1A5276' if f in SOFA_SET else '#1E8449' for f in top.index]\n",
    "        ax.barh(range(len(top)), top.values, color=colors, edgecolor='white', height=0.7)\n",
    "        ax.set_yticks(range(len(top)))\n",
    "        ax.set_yticklabels(top.index, fontsize=9)\n",
    "        ax.set_xlabel('Mean |SHAP value|', fontsize=9)\n",
    "        ax.set_title(f'SOFA {sev}', fontweight='bold', fontsize=10)\n",
    "    patch1 = mpatches.Patch(color='#1A5276', label='LODS proxy (SOFA subscores)')\n",
    "    patch2 = mpatches.Patch(color='#1E8449', label='APS III proxy (labs/vitals)')\n",
    "    fig.legend(handles=[patch1,patch2], fontsize=9,\n",
    "               loc='lower center', bbox_to_anchor=(0.5,-0.05), ncol=2)\n",
    "    fig.suptitle(f'{care_label} \u2014 SHAP Feature Importance | {model_name}',\n",
    "                 fontsize=12, fontweight='bold')\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(save_path, bbox_inches='tight', dpi=150)\n",
    "    plt.show()\n",
    "    print(f'  Saved: {save_path}')\n",
    "\n",
    "for care in ['Mouthcare','Turning']:\n",
    "    for mname, mshort in [('A \u2013 All Quartiles','A'),('B \u2013 Q1 Only','B')]:\n",
    "        plot_shap_grid(care, mname,\n",
    "                       os.path.join(OUTPUT_FOLDER, f'fig4_shap_{care.lower()}_model{mshort}.png'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 13. Results Export"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "HDR_BG='1F3864'; HDR_FG='FFFFFF'; DARK_BG='2E4057'; BORDER='BDC3C7'\n",
    "SEV_BG  = {'Low':'EBF5FB','Medium':'FEF9E7','High':'FDEDEC'}\n",
    "MOD_BG  = {'A \u2013 All Quartiles':'D6E4F0','B \u2013 Q1 Only':'D5F5E3'}\n",
    "thin    = Border(left=Side('thin',color=BORDER),right=Side('thin',color=BORDER),\n",
    "                 top=Side('thin',color=BORDER), bottom=Side('thin',color=BORDER))\n",
    "\n",
    "DISP_COLS = ['Care Type','Severity','Model','Test Set','N','Mortality%',\n",
    "             'AUROC_CI','Sensitivity','Specificity','PPV','NPV','F1']\n",
    "DISP_COLS = [c for c in DISP_COLS if c in results_df.columns]\n",
    "COL_W     = {'Care Type':13,'Severity':10,'Model':22,'Test Set':20,'N':7,\n",
    "             'Mortality%':12,'AUROC_CI':28,'Sensitivity':28,'Specificity':28,\n",
    "             'PPV':28,'NPV':28,'F1':28}\n",
    "\n",
    "def write_sheet(ws, df, title):\n",
    "    cols = list(df.columns); nc = len(cols)\n",
    "    ws.merge_cells(start_row=1,start_column=1,end_row=1,end_column=nc)\n",
    "    c=ws.cell(1,1,title)\n",
    "    c.font=Font('Calibri',bold=True,size=13,color=HDR_FG)\n",
    "    c.fill=PatternFill('solid',fgColor=DARK_BG)\n",
    "    c.alignment=Alignment(horizontal='center',vertical='center')\n",
    "    ws.row_dimensions[1].height=24\n",
    "    for ci,cn in enumerate(cols,1):\n",
    "        c=ws.cell(2,ci,cn)\n",
    "        c.font=Font('Calibri',bold=True,size=10,color=HDR_FG)\n",
    "        c.fill=PatternFill('solid',fgColor=HDR_BG)\n",
    "        c.alignment=Alignment(horizontal='center',vertical='center',wrap_text=True)\n",
    "        c.border=thin\n",
    "    ws.row_dimensions[2].height=34\n",
    "    for ri,(_,row) in enumerate(df.iterrows(),3):\n",
    "        sev=str(row.get('Severity',''))\n",
    "        mod=str(row.get('Model',''))\n",
    "        bg=MOD_BG.get(mod, SEV_BG.get(sev,'F8F9FA'))\n",
    "        for ci,cn in enumerate(cols,1):\n",
    "            val=row[cn]; c=ws.cell(ri,ci,val)\n",
    "            c.font=Font('Calibri',size=10,bold=(cn=='AUROC_CI'))\n",
    "            c.fill=PatternFill('solid',fgColor=bg)\n",
    "            c.border=thin\n",
    "            c.alignment=Alignment(\n",
    "                horizontal='left' if cn in ('Care Type','Severity','Model','Test Set') else 'center',\n",
    "                vertical='center')\n",
    "        ws.row_dimensions[ri].height=18\n",
    "    for ci,cn in enumerate(cols,1):\n",
    "        ws.column_dimensions[get_column_letter(ci)].width=COL_W.get(cn,14)\n",
    "    ws.freeze_panes='A3'\n",
    "\n",
    "display_df = results_df[DISP_COLS]\n",
    "wb = Workbook()\n",
    "wb.remove(wb.active)\n",
    "\n",
    "sheets = [\n",
    "    ('All Results',     display_df,  'All Results \u2014 Mouthcare & Turning'),\n",
    "    ('Mortality Table', mort_tbl,    'Mortality by Severity \u00d7 Quartile (within-severity Q assignment)'),\n",
    "]\n",
    "for care in ['Mouthcare','Turning']:\n",
    "    for sev in SEVERITY_LABELS:\n",
    "        sub = display_df[\n",
    "            (display_df['Care Type']==care) & (display_df['Severity']==sev)\n",
    "        ]\n",
    "        if len(sub)==0: continue\n",
    "        sofa_range = {'Low':'0\u20136','Medium':'7\u201311','High':'\u226512'}[sev]\n",
    "        sheets.append((\n",
    "            f'{care[:4]} \u2013 {sev}',\n",
    "            sub,\n",
    "            f'{care} | {sev} Severity (SOFA {sofa_range})'\n",
    "        ))\n",
    "\n",
    "for sname, df_s, title in sheets:\n",
    "    ws = wb.create_sheet(title=sname)\n",
    "    write_sheet(ws, df_s.reset_index(drop=True), title)\n",
    "    print(f'   Sheet \"{sname}\" ({len(df_s)} rows)')\n",
    "\n",
    "wb.save(OUTPUT_EXCEL)\n",
    "print(f'\\n Excel saved : {os.path.abspath(OUTPUT_EXCEL)}')\n",
    "print(f' Figures in  : {os.path.abspath(OUTPUT_FOLDER)}/')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 14. Interpretation Framework\n",
    "\n",
    "### Primary evidence criteria\n",
    "\n",
    "| Evidence | Source | Criterion supporting hypothesis |\n",
    "|---|---|---|\n",
    "| Mortality gradient | Section 8 \u2014 Mortality Table | Mortality rate increases Q1 to Q4 within each severity stratum |\n",
    "| Severity balance | Section 5 output | Mean SOFA score is comparable across Q1\u2013Q4 within each stratum |\n",
    "| Model B discrimination | Section 9\u201310 \u2014 AUROC plots | AUROC decreases from Q1 to Q4 for Model B within each severity stratum |\n",
    "| Calibration breakdown | Section 11 \u2014 Calibration curves | Q3/Q4 points fall above the diagonal for Model B |\n",
    "| Feature validity | Section 12 \u2014 SHAP | SOFA subscores and clinical severity features dominate model predictions |\n",
    "\n",
    "---\n",
    "\n",
    "### Definitions\n",
    "\n",
    "- **Q1**: Highest care frequency (smallest mean interval between care events)\n",
    "- **Q4**: Lowest care frequency (largest mean interval between care events)\n",
    "- **Severity strata**: Low = SOFA 0\u20136 | Medium = SOFA 7\u201311 | High = SOFA \u226512\n",
    "\n",
    "---\n",
    "\n",
    "### Justification of SOFA cut-points\n",
    "\n",
    "The severity cut-points used in this analysis align with the Sepsis-3 consensus definition (Singer et al., *JAMA*, 2016), in which a SOFA score \u22652 defines acute organ dysfunction. The thresholds of 0\u20136 (low), 7\u201311 (medium), and \u226512 (high) reflect clinically meaningful strata corresponding to absent or minimal dysfunction, moderate multi-organ failure, and severe dysfunction with substantially elevated predicted mortality, respectively. The use of pre-specified, clinically grounded cut-points avoids data-driven threshold selection and supports comparability with published critical care literature."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}